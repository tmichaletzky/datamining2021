{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FvpHOWd2pIUL"
   },
   "source": [
    "# DataMining - BERT\n",
    "\n",
    "https://github.com/huggingface/notebooks/blob/master/examples/text_classification-tf.ipynb\n",
    "\n",
    "https://www.tensorflow.org/text/tutorials/classify_text_with_bert\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LJRaUPtiHw6p"
   },
   "source": [
    "# Setup Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XV-r0iqUHQZ4",
    "outputId": "2b1b456a-11da-45d5-cbff-491e6e8a9f3b"
   },
   "source": [
    "    !pip install kaggle\n",
    "\n",
    "    !mkdir ~/.kaggle\n",
    "\n",
    "    !cp \"drive/MyDrive/Colab Notebooks/DataMining/kaggle.json\" ~/.kaggle/\n",
    "\n",
    "    !chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "    !kaggle datasets download -d cosmos98/twitter-and-reddit-sentimental-analysis-dataset\n",
    "\n",
    "    !unzip /content/twitter-and-reddit-sentimental-analysis-dataset.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CwvkY4KgtqiF"
   },
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "VmwQUpocs4gE"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing\n",
    "import os, time\n",
    "#import tweepy as tw #for accessing Twitter API\n",
    "\n",
    "# For Building the model\n",
    "from sklearn.model_selection import train_test_split\n",
    "#import tensorflow as tf\n",
    "import seaborn as sns\n",
    "\n",
    "#For data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wrxhs68Bs4gH"
   },
   "source": [
    "# Read and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "FMxUmwZTs4gL",
    "outputId": "9556c746-1642-4321-998d-d247de6527df"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>family mormon have never tried explain them t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buddhism has very much lot compatible with chr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seriously don say thing first all they won get...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what you have learned yours and only yours wha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>for your own benefit you may want read living ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>you should all sit down together and watch the...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>was teens when discovered zen meditation was ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>jesus was zen meets jew</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>there are two varieties christians dogmatic th...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dont worry about trying explain yourself just ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  score\n",
       "0   family mormon have never tried explain them t...      1\n",
       "1  buddhism has very much lot compatible with chr...      1\n",
       "2  seriously don say thing first all they won get...     -1\n",
       "3  what you have learned yours and only yours wha...      0\n",
       "4  for your own benefit you may want read living ...      1\n",
       "5  you should all sit down together and watch the...     -1\n",
       "6   was teens when discovered zen meditation was ...      1\n",
       "7                           jesus was zen meets jew       0\n",
       "8  there are two varieties christians dogmatic th...     -1\n",
       "9  dont worry about trying explain yourself just ...      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/Reddit_Data.csv\")\n",
    "df = df.rename(columns={'clean_comment':'text', 'category':'score'})\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "t8jmyS_ao-sy"
   },
   "outputs": [],
   "source": [
    "def score2label(y):\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yvGh-dBus4gQ",
    "outputId": "dfbd8100-4304-4943-8d58-86031858eaec",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "score    37249.0\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().loc[\"count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yqPLZ_mos4gR",
    "outputId": "2ca7d5e5-768b-4b44-c68b-f6d2a02e59d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     100\n",
       "score      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum() #100 adat hiányzik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "hzv3o-cMs4gT"
   },
   "outputs": [],
   "source": [
    "df.dropna(axis=0, inplace=True) #NA adatok eldobása"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "teWlu6Rys4gU",
    "outputId": "669b600c-2d4b-4150-a1e9-09aaf0441c9b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37149, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "taxIdHywp0w-"
   },
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bgZCs2nSfe01",
    "outputId": "d68ee98c-9fb8-4678-acc0-878cb3515f9f"
   },
   "source": [
    "    !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iIN8uIgaNzC1",
    "outputId": "27b0b594-3d29-4542-8d02-c95887bc65e0"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-ea26f191260c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TensorFlow version: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Transformers version: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow version: \", tf.__version__)\n",
    "from tensorflow.data import Dataset\n",
    "import transformers\n",
    "print(\"Transformers version: \", transformers.__version__)\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import create_optimizer\n",
    "\n",
    "print(\"\\nNum GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Q_wK8w9gSdG"
   },
   "source": [
    "# Text preprocess\n",
    "\n",
    "Load data: https://www.tensorflow.org/tutorials/load_data/numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "mamdohMb1HQ_"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "JuePftJJg1CV"
   },
   "outputs": [],
   "source": [
    "BERT_MODEL = \"bert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "fbmMj2XUOKFn"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "6tws_4Tr6Yp2"
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "  return tokenizer(text,\n",
    "          #do_lower_case=True,\n",
    "          add_special_tokens=True,\n",
    "          padding=\"max_length\",\n",
    "          max_length=250,\n",
    "          truncation=True,\n",
    "          return_tensors=\"np\",\n",
    "          return_token_type_ids=False,\n",
    "          return_attention_mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "wJRoIUb61kRa"
   },
   "outputs": [],
   "source": [
    "XX_tr, XX_te, y_train, y_test = train_test_split(df[\"text\"].to_list(), df[\"score\"].to_numpy()+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "fkzuJEcGOVEj"
   },
   "outputs": [],
   "source": [
    "X_tr_encoded = tokenize(XX_tr)\n",
    "X_te_encoded = tokenize(XX_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "A7Zu79tUsW2i"
   },
   "outputs": [],
   "source": [
    "X_train = (X_tr_encoded[\"input_ids\"], X_tr_encoded[\"attention_mask\"])\n",
    "X_test = (X_te_encoded[\"input_ids\"], X_te_encoded[\"attention_mask\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v9wxOGg9gvQY"
   },
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xvAb3OoVzxTZ",
    "outputId": "a76fef5e-43fa-4464-827c-af995e64760d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow_addons in /usr/local/lib/python3.7/dist-packages (0.14.0)\n",
      "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_UekJyYfxOiB",
    "outputId": "2440409c-3e07-4607-e5d1-b8656beadfe0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:67: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.4.0 and strictly below 2.7.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.7.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras as keras\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "We8rk0_fUazD"
   },
   "outputs": [],
   "source": [
    "NUM_LABELS = 3\n",
    "EPOCHS = 5\n",
    "LR_RATE = 2e-5\n",
    "BATCHES = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hAA6SNvBVHfs",
    "outputId": "50028978-6a25-4b8d-b953-6ad4b2509154"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = TFAutoModelForSequenceClassification.from_pretrained(BERT_MODEL, num_labels=NUM_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "Gx3Gz7qZxNCz"
   },
   "outputs": [],
   "source": [
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=LR_RATE,\n",
    "    decay_steps=int(len(y_train) * EPOCHS / BATCHES),\n",
    "    decay_rate=0.9)\n",
    "optimizer = keras.optimizers.SGD(learning_rate=lr_schedule, clipnorm=1)\n",
    "#optimizer, _ = create_optimizer(init_lr=LR_RATE, num_warmup_steps=0, num_train_steps=int(SAMPLE_SIZE // BATCHES * EPOCHS))\n",
    "criterion = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "-JHbuhD-xoDG"
   },
   "outputs": [],
   "source": [
    "metrics = [#keras.metrics.AUC(multi_label=True, num_labels=3, from_logits=True), \n",
    "           #tfa.metrics.F1Score(num_classes=3, average=\"macro\")\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "4cBtbpfidIEL"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, loss=criterion, metrics=[\"acc\", \"ce\", \"mse\"]+metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "o_iKIV7Fd1UP",
    "outputId": "a9d552b1-1c6b-4bf4-ee98-997ea096a1ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-cabf7bd3c53c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCHES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m           validation_split=0.2) \n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m#https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[8000,3072] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node tf_bert_for_sequence_classification/bert/encoder/layer_._10/intermediate/dense/Tensordot/MatMul\n (defined at /usr/local/lib/python3.7/dist-packages/keras/layers/core/dense.py:202)\n]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_28261]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node tf_bert_for_sequence_classification/bert/encoder/layer_._10/intermediate/dense/Tensordot/MatMul:\nIn[0] tf_bert_for_sequence_classification/bert/encoder/layer_._10/intermediate/dense/Tensordot/Reshape:\t\nIn[1] tf_bert_for_sequence_classification/bert/encoder/layer_._10/intermediate/dense/Tensordot/ReadVariableOp:\n\nOperation defined at: (most recent call last)\n>>>   File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n>>>     \"__main__\", mod_spec)\n>>> \n>>>   File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n>>>     ret = callback()\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n>>>     self.io_loop.add_callback(lambda: self._handle_events(self.socket, 0))\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 452, in _handle_events\n>>>     self._handle_recv()\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 481, in _handle_recv\n>>>     self._run_callback(callback, msg)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 431, in _run_callback\n>>>     callback(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n>>>     return self.dispatch_shell(stream, msg)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n>>>     handler(stream, idents, msg)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n>>>     user_expressions, allow_stdin)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n>>>     interactivity=interactivity, compiler=compiler, result=result)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n>>>     if self.run_code(code, result):\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"<ipython-input-30-cabf7bd3c53c>\", line 6, in <module>\n>>>     validation_split=0.2)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/transformers/modeling_tf_utils.py\", line 796, in train_step\n>>>     y_pred = self(x, training=True)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_tf_bert.py\", line 1749, in call\n>>>     outputs = self.bert(\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_tf_bert.py\", line 870, in call\n>>>     encoder_outputs = self.encoder(\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_tf_bert.py\", line 537, in call\n>>>     for i, layer_module in enumerate(self.layer):\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_tf_bert.py\", line 543, in call\n>>>     layer_outputs = layer_module(\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_tf_bert.py\", line 499, in call\n>>>     intermediate_output = self.intermediate(hidden_states=attention_output)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_tf_bert.py\", line 402, in call\n>>>     hidden_states = self.dense(inputs=hidden_states)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/layers/core/dense.py\", line 202, in call\n>>>     outputs = tf.tensordot(inputs, self.kernel, [[rank - 1], [0]])\n>>> "
     ]
    }
   ],
   "source": [
    "train_history = model.fit(X_train,\n",
    "          y_train, \n",
    "          epochs=EPOCHS, \n",
    "          batch_size=BATCHES, \n",
    "          shuffle=True,\n",
    "          validation_split=0.2) \n",
    "#https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wBLWaNNfwafL"
   },
   "outputs": [],
   "source": [
    "train_history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LPNe3vLveoxq"
   },
   "outputs": [],
   "source": [
    "test_history = model.evaluate(X_train, y_train, \n",
    "               batch_size=BATCHES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uesnpFfLtT-6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DataMining - Bert.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
